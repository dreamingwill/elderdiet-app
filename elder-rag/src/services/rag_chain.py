"""
RAG Chain æ ¸å¿ƒç³»ç»Ÿ
å®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆçš„å®Œæ•´æµç¨‹ï¼šæŸ¥è¯¢åˆ†æ â†’ çŸ¥è¯†æ£€ç´¢ â†’ Promptç”Ÿæˆ â†’ å›ç­”ç”Ÿæˆ â†’ è´¨é‡è¯„ä¼°

æ³¨æ„ï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿå›ç­”ç”Ÿæˆå™¨ï¼Œå¯æ›¿æ¢ä¸ºçœŸå®LLM APIè°ƒç”¨
"""

import time
import json
import os
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

from .vector_store import VectorStore
from .retriever import ElderNutritionRetriever, SearchConfig, SearchStrategy, SearchResult
from .prompt_manager import PromptManager
from .prompt_template import QueryIntent


class RAGMode(Enum):
    """RAGæ¨¡å¼æšä¸¾"""
    BASIC = "basic"                    # åŸºç¡€æ¨¡å¼ï¼šç®€å•æ£€ç´¢+ç”Ÿæˆ
    ENHANCED = "enhanced"              # å¢å¼ºæ¨¡å¼ï¼šæ™ºèƒ½æ£€ç´¢+Few-shot
    EXPERT = "expert"                  # ä¸“å®¶æ¨¡å¼ï¼šå¤šè½®ä¼˜åŒ–+è´¨é‡ä¿éšœ
    INTERACTIVE = "interactive"        # äº¤äº’æ¨¡å¼ï¼šå¯¹è¯å¼é—®ç­”


@dataclass
class RAGConfig:
    """RAGé…ç½®"""
    mode: RAGMode = RAGMode.ENHANCED
    
    # æ£€ç´¢é…ç½®
    search_strategy: SearchStrategy = SearchStrategy.HYBRID
    top_k: int = 3
    similarity_threshold: float = 0.3
    enable_reranking: bool = True
    
    # Prompté…ç½®
    use_few_shot: bool = True
    enable_quality_check: bool = True
    
    # ç”Ÿæˆé…ç½®
    max_response_length: int = 1000
    response_style: str = "professional"  # professional, friendly, detailed
    include_sources: bool = True
    
    # è´¨é‡é…ç½®
    min_quality_score: float = 70.0
    enable_auto_retry: bool = True
    max_retry_attempts: int = 2
    
    # LLMé…ç½® (æ–°å¢)
    use_real_llm: bool = False          # æ˜¯å¦ä½¿ç”¨çœŸå®LLM
    llm_provider: str = "openai"        # LLMæä¾›å•†: openai, anthropic, qwen, etc.
    llm_model: str = "gpt-4"           # æ¨¡å‹åç§°
    llm_api_key: Optional[str] = None   # APIå¯†é’¥
    llm_base_url: Optional[str] = None  # è‡ªå®šä¹‰APIåœ°å€


@dataclass
class RAGContext:
    """RAGä¸Šä¸‹æ–‡ä¿¡æ¯"""
    user_query: str
    session_id: str
    conversation_history: List[Dict[str, Any]] = field(default_factory=list)
    user_profile: Optional[Dict[str, Any]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RAGResponse:
    """RAGå“åº”ç»“æœ"""
    query: str
    answer: str
    sources: List[SearchResult]
    confidence_score: float
    quality_score: float
    processing_time: float
    intent: QueryIntent
    prompt_used: str
    metadata: Dict[str, Any] = field(default_factory=dict)


class ResponseGenerator:
    """å›ç­”ç”Ÿæˆå™¨ï¼ˆæ”¯æŒæ¨¡æ‹Ÿå’ŒçœŸå®LLMï¼‰"""
    
    def __init__(self, config: RAGConfig = None):
        self.config = config or RAGConfig()
        self.response_templates = self._load_response_templates()
        
        # å¦‚æœå¯ç”¨çœŸå®LLMï¼Œåˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        if self.config.use_real_llm:
            self._init_llm_client()
    
    def _init_llm_client(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        if self.config.llm_provider == "openai":
            try:
                import openai
                self.llm_client = openai.OpenAI(
                    api_key=self.config.llm_api_key or os.getenv("OPENAI_API_KEY"),
                    base_url=self.config.llm_base_url
                )
            except ImportError:
                print("âš ï¸ openaiåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")
                self.config.use_real_llm = False
        
        elif self.config.llm_provider == "anthropic":
            try:
                import anthropic
                self.llm_client = anthropic.Anthropic(
                    api_key=self.config.llm_api_key or os.getenv("ANTHROPIC_API_KEY")
                )
            except ImportError:
                print("âš ï¸ anthropicåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install anthropic")
                self.config.use_real_llm = False
        
        elif self.config.llm_provider == "qwen":
            # é€šä¹‰åƒé—®ç­‰å›½äº§æ¨¡å‹çš„æ¥å…¥ç¤ºä¾‹
            # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“APIè¿›è¡Œå®ç°
            print("ğŸš§ é€šä¹‰åƒé—®æ¥å…¥å¼€å‘ä¸­...")
            self.config.use_real_llm = False
        
        else:
            print(f"âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {self.config.llm_provider}")
            self.config.use_real_llm = False
    
    def generate_response(
        self, 
        prompt: str, 
        config: RAGConfig,
        context: RAGContext
    ) -> Tuple[str, float]:
        """
        ç”Ÿæˆå›ç­”ï¼ˆæ”¯æŒçœŸå®LLMå’Œæ¨¡æ‹ŸLLMï¼‰
        
        Args:
            prompt: ç”Ÿæˆçš„prompt
            config: RAGé…ç½®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            (å›ç­”æ–‡æœ¬, ç½®ä¿¡åº¦åˆ†æ•°)
        """
        if config.use_real_llm and hasattr(self, 'llm_client'):
            # ä½¿ç”¨çœŸå®LLMç”Ÿæˆå›ç­”
            return self._generate_with_real_llm(prompt, config, context)
        else:
            # ä½¿ç”¨æ¨¡æ‹Ÿå›ç­”ç”Ÿæˆå™¨
            return self._generate_with_simulation(prompt, config, context)
    
    def _generate_with_real_llm(
        self,
        prompt: str,
        config: RAGConfig,
        context: RAGContext
    ) -> Tuple[str, float]:
        """ä½¿ç”¨çœŸå®LLMç”Ÿæˆå›ç­”"""
        try:
            if config.llm_provider == "openai":
                response = self.llm_client.chat.completions.create(
                    model=config.llm_model,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=config.max_response_length,
                    temperature=0.7
                )
                answer = response.choices[0].message.content
                confidence = 0.9  # åŸºäºçœŸå®LLMçš„é«˜ç½®ä¿¡åº¦
                
            elif config.llm_provider == "anthropic":
                message = self.llm_client.messages.create(
                    model=config.llm_model,
                    max_tokens=config.max_response_length,
                    messages=[
                        {"role": "user", "content": prompt}
                    ]
                )
                answer = message.content[0].text
                confidence = 0.9
            
            else:
                # å…¶ä»–æä¾›å•†çš„å®ç°
                raise NotImplementedError(f"LLMæä¾›å•† {config.llm_provider} å°šæœªå®ç°")
            
            return answer, confidence
            
        except Exception as e:
            print(f"âŒ LLM APIè°ƒç”¨å¤±è´¥: {str(e)}")
            print("ğŸ”„ å›é€€åˆ°æ¨¡æ‹Ÿå›ç­”ç”Ÿæˆå™¨")
            return self._generate_with_simulation(prompt, config, context)
    
    def _generate_with_simulation(
        self,
        prompt: str,
        config: RAGConfig,
        context: RAGContext
    ) -> Tuple[str, float]:
        """ä½¿ç”¨æ¨¡æ‹Ÿå›ç­”ç”Ÿæˆå™¨ï¼ˆå½“å‰é»˜è®¤æ–¹å¼ï¼‰"""
        # åŸºäºpromptå†…å®¹ç”Ÿæˆæ¨¡æ‹Ÿå›ç­”
        if "ç³–å°¿ç—…" in prompt:
            answer = self._generate_diabetes_response(prompt, config)
        elif "ç¼ºé’™" in prompt or "é’™è´¨" in prompt:
            answer = self._generate_calcium_response(prompt, config)
        elif "é«˜è¡€å‹" in prompt:
            answer = self._generate_hypertension_response(prompt, config)
        elif "é£Ÿè°±" in prompt or "é¥®é£Ÿè®¡åˆ’" in prompt:
            answer = self._generate_diet_plan_response(prompt, config)
        else:
            answer = self._generate_general_response(prompt, config)
        
        # æ ¹æ®é…ç½®è°ƒæ•´å›ç­”é£æ ¼
        answer = self._adjust_response_style(answer, config.response_style)
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºpromptè´¨é‡å’Œå†…å®¹åŒ¹é…åº¦ï¼‰
        confidence = self._calculate_confidence(prompt, answer)
        
        return answer, confidence
    
    def _generate_diabetes_response(self, prompt: str, config: RAGConfig) -> str:
        """ç”Ÿæˆç³–å°¿ç—…ç›¸å…³å›ç­”"""
        base_response = """æ‚¨å¥½ï¼å…³äºç³–å°¿ç—…è€å¹´äººçš„é¥®é£Ÿç®¡ç†ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹ä¸“ä¸šå»ºè®®ï¼š

**æ ¸å¿ƒé¥®é£ŸåŸåˆ™**ï¼š
1. **æ§åˆ¶æ€»çƒ­é‡**ï¼šæ ¹æ®ä½“é‡å’Œæ´»åŠ¨é‡ï¼Œå»ºè®®æ¯æ—¥1600-1800åƒå¡
2. **é€‰æ‹©ä½ç³–æŒ‡æ•°é£Ÿç‰©**ï¼šä¼˜é€‰ç‡•éº¦ã€ç³™ç±³ã€å…¨éº¦åˆ¶å“
3. **å¢åŠ è†³é£Ÿçº¤ç»´**ï¼šæ¯æ—¥25-30å…‹ï¼Œå¤šé£Ÿç”¨ç»¿å¶è”¬èœå’Œè±†ç±»
4. **å®šæ—¶å®šé‡è¿›é¤**ï¼šå»ºè®®ä¸‰é¤åŠ ä¸¤æ¬¡å¥åº·åŠ é¤ï¼Œè§„å¾‹é¥®é£Ÿ

**æ¨èé£Ÿç‰©æ­é…**ï¼š
- **ä¸»é£Ÿ**ï¼šç‡•éº¦ç‰‡ã€ç³™ç±³é¥­ã€å…¨éº¦é¢æ¡ï¼ˆæ¯é¤100-150gï¼‰
- **è›‹ç™½è´¨**ï¼šç˜¦è‚‰ã€é±¼ç±»ã€è±†è…ã€é¸¡è›‹ï¼ˆæ¯æ—¥100-150gï¼‰
- **è”¬èœ**ï¼šè èœã€è¥¿å…°èŠ±ã€èŠ¹èœã€é»„ç“œï¼ˆæ¯æ—¥400-500gï¼‰
- **æ°´æœ**ï¼šè‹¹æœã€æ¢¨ã€æŸšå­ï¼ˆæ¯æ—¥100-200gï¼Œæ§åˆ¶ç³–åˆ†ï¼‰

**é‡è¦æ³¨æ„äº‹é¡¹**ï¼š
- å®šæœŸç›‘æµ‹è¡€ç³–å˜åŒ–ï¼Œè®°å½•é¥®é£Ÿä¸è¡€ç³–çš„å…³ç³»
- è¯ç‰©è°ƒæ•´éœ€å’¨è¯¢å†…åˆ†æ³Œç§‘åŒ»ç”Ÿ
- å‡ºç°ä½è¡€ç³–ç—‡çŠ¶æ—¶åŠæ—¶å¤„ç†
- é…åˆé€‚é‡è¿åŠ¨ï¼Œä¿ƒè¿›è¡€ç³–æ§åˆ¶

å¸Œæœ›è¿™äº›å»ºè®®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼å¦‚æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å’¨è¯¢ã€‚"""
        
        return base_response
    
    def _generate_calcium_response(self, prompt: str, config: RAGConfig) -> str:
        """ç”Ÿæˆè¡¥é’™ç›¸å…³å›ç­”"""
        base_response = """æ‚¨å¥½ï¼è€å¹´äººé’™è´¨è¡¥å……ç¡®å®å¾ˆé‡è¦ï¼Œæˆ‘ä¸ºæ‚¨åˆ¶å®šç§‘å­¦çš„è¡¥é’™æ–¹æ¡ˆï¼š

**ä¸ºä»€ä¹ˆè€å¹´äººå®¹æ˜“ç¼ºé’™**ï¼š
éšç€å¹´é¾„å¢é•¿ï¼Œé’™çš„å¸æ”¶ç‡ä¸‹é™ï¼ŒåŒæ—¶æµå¤±å¢åŠ ï¼Œå®¹æ˜“å¯¼è‡´éª¨è´¨ç–æ¾ã€‚

**å¤©ç„¶é£Ÿç‰©è¡¥é’™æ–¹æ¡ˆ**ï¼š
1. **å¥¶åˆ¶å“**ï¼ˆæ¯æ—¥250-500mlï¼‰
   - ç‰›å¥¶ã€é…¸å¥¶ã€å¥¶é…ª
   - æ¯100mlç‰›å¥¶å«é’™çº¦100mg

2. **è±†åˆ¶å“**ï¼ˆæ¯æ—¥100-150gï¼‰
   - è±†è…ã€è±†å¹²ã€è±†æµ†
   - 100gè±†è…å«é’™çº¦150mg

3. **ç»¿å¶è”¬èœ**ï¼ˆæ¯æ—¥200-300gï¼‰
   - è èœã€å°ç™½èœã€èŠ¥è“
   - é’™å«é‡é«˜ä¸”å¸æ”¶ç‡å¥½

4. **å°é±¼å°è™¾**ï¼ˆæ¯å‘¨2-3æ¬¡ï¼‰
   - å¸¦éª¨å°é±¼ã€è™¾çš®
   - ä¼˜è´¨é’™æº

**ä¿ƒè¿›å¸æ”¶çš„æ–¹æ³•**ï¼š
- é€‚é‡æ™’å¤ªé˜³ï¼Œè¡¥å……ç»´ç”Ÿç´ D
- é€‚åº¦è¿åŠ¨ï¼Œä¿ƒè¿›éª¨éª¼å¥åº·
- é¿å…ä¸å’–å•¡ã€èŒ¶åŒæ—¶å¤§é‡é¥®ç”¨

**æ¯æ—¥æ¨èæ­é…**ï¼š
- æ—©é¤ï¼šç‰›å¥¶250ml + è±†æµ†200ml
- åˆé¤ï¼šå°ç™½èœ100g + è±†è…50g
- æ™šé¤ï¼šè èœ150g + è™¾çš®5g

è¿™æ ·å¯è¾¾åˆ°æ¯æ—¥1000-1200mgçš„æ¨èæ‘„å…¥é‡ã€‚"""
        
        return base_response
    
    def _generate_hypertension_response(self, prompt: str, config: RAGConfig) -> str:
        """ç”Ÿæˆé«˜è¡€å‹ç›¸å…³å›ç­”"""
        base_response = """æ‚¨å¥½ï¼é«˜è¡€å‹è€å¹´äººçš„é¥®é£Ÿç®¡ç†éå¸¸é‡è¦ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä¸“ä¸šæŒ‡å¯¼ï¼š

**é™å‹é¥®é£ŸåŸåˆ™**ï¼š
1. **ä½ç›é¥®é£Ÿ**ï¼šæ¯æ—¥ç›åˆ†æ§åˆ¶åœ¨5-6gä»¥å†…
2. **å¢åŠ é’¾æ‘„å…¥**ï¼šå¤šé£Ÿç”¨é¦™è•‰ã€åœŸè±†ã€è¥¿çº¢æŸ¿
3. **æ§åˆ¶è„‚è‚ª**ï¼šå‡å°‘é¥±å’Œè„‚è‚ªï¼Œé€‰æ‹©æ©„æ¦„æ²¹ç­‰å¥åº·æ²¹è„‚
4. **é€‚é‡è›‹ç™½è´¨**ï¼šé±¼ç±»ã€è±†ç±»ä¸ºä¸»è¦æ¥æº

**æ¨èé£Ÿç‰©**ï¼š
- **è°·ç‰©**ï¼šç‡•éº¦ã€ç³™ç±³ã€å…¨éº¦åˆ¶å“
- **è”¬èœ**ï¼šèŠ¹èœã€è èœã€å†¬ç“œã€é»„ç“œï¼ˆæ¯æ—¥400-500gï¼‰
- **æ°´æœ**ï¼šé¦™è•‰ã€è‹¹æœã€æ©™å­ï¼ˆæ¯æ—¥200-300gï¼‰
- **è›‹ç™½è´¨**ï¼šæ·±æµ·é±¼ã€é¸¡èƒ¸è‚‰ã€è±†è…

**çƒ¹é¥ªå»ºè®®**ï¼š
- å¤šç”¨è’¸ã€ç…®ã€ç‚–çš„æ–¹å¼ï¼Œå‡å°‘æ²¹ç‚¸
- ç”¨å¤©ç„¶é¦™æ–™è°ƒå‘³ï¼šå§œã€è’œã€èƒ¡æ¤’
- å¤šç”¨é†‹ã€æŸ æª¬æ±æå‘³
- é£Ÿç”¨æ²¹æ¯æ—¥ä¸è¶…è¿‡25g

**æ³¨æ„äº‹é¡¹**ï¼š
- å®šæœŸç›‘æµ‹è¡€å‹å˜åŒ–
- é…åˆé€‚é‡è¿åŠ¨
- è¯ç‰©æ²»ç–—éœ€éµåŒ»å˜±
- ä¿æŒæƒ…ç»ªç¨³å®šï¼Œé¿å…å‹åŠ›"""
        
        return base_response
    
    def _generate_diet_plan_response(self, prompt: str, config: RAGConfig) -> str:
        """ç”Ÿæˆé¥®é£Ÿè§„åˆ’å›ç­”"""
        base_response = """æ‚¨å¥½ï¼æˆ‘ä¸ºæ‚¨åˆ¶å®šä¸€ä¸ªè¥å…»å‡è¡¡çš„è€å¹´äººä¸€æ—¥é¥®é£Ÿè®¡åˆ’ï¼š

**è¥å…»ç›®æ ‡**ï¼š
- æ€»çƒ­é‡ï¼š1600-1800kcal
- è›‹ç™½è´¨ï¼šæ¯å…¬æ–¤ä½“é‡1.0-1.2g
- è†³é£Ÿçº¤ç»´ï¼š25-30g
- æ°´åˆ†ï¼š1200-1500ml

**ä¸€æ—¥é£Ÿè°±å®‰æ’**ï¼š

**æ—©é¤ï¼ˆ7:00-8:00ï¼‰**ï¼š
- å°ç±³ç²¥ 150ml
- ç…®é¸¡è›‹ 1ä¸ª
- å‡‰æ‹Œé»„ç“œ 100g
- ç‰›å¥¶ 250ml

**ä¸ŠåˆåŠ é¤ï¼ˆ10:00ï¼‰**ï¼š
- è‹¹æœ 150g æˆ–é¦™è•‰ 100g

**åˆé¤ï¼ˆ12:00-13:00ï¼‰**ï¼š
- äºŒç±³é¥­ 100g
- æ¸…è’¸é±¼ 100g
- ç‚’æ—¶è”¬ 150g
- ç´«èœè›‹èŠ±æ±¤ 200ml

**ä¸‹åˆåŠ é¤ï¼ˆ15:30ï¼‰**ï¼š
- æ— ç³–é…¸å¥¶ 150ml
- æ ¸æ¡ƒ 3ä¸ª

**æ™šé¤ï¼ˆ18:00-19:00ï¼‰**ï¼š
- ç‡•éº¦ç²¥ 150ml
- æ¸…ç‚’è èœ 150g
- æ¸…ç‚–è±†è… 100g
- é“¶è€³æ±¤ 200ml

**åˆ¶ä½œè¦ç‚¹**ï¼š
1. å°‘æ²¹å°‘ç›ï¼Œæ¸…æ·¡ä¸ºä¸»
2. é£Ÿææ–°é²œï¼Œæ­é…å¤šæ ·
3. ç»†åš¼æ…¢å’½ï¼Œå®šæ—¶è¿›é¤
4. é€‚é‡é¥®æ°´ï¼Œé¿å…è¿‡é¥±"""
        
        return base_response
    
    def _generate_general_response(self, prompt: str, config: RAGConfig) -> str:
        """ç”Ÿæˆé€šç”¨è¥å…»å›ç­”"""
        base_response = """æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨çš„è¥å…»å’¨è¯¢ã€‚

**ä¸€èˆ¬è¥å…»å»ºè®®**ï¼š
1. **å‡è¡¡é¥®é£Ÿ**ï¼šç¡®ä¿å„ç±»è¥å…»ç´ æ‘„å…¥å……è¶³
2. **å¤šæ ·åŒ–é€‰æ‹©**ï¼šæ¯æ—¥æ‘„å…¥å¤šç§é¢œè‰²çš„è”¬èœæ°´æœ
3. **é€‚é‡è¿åŠ¨**ï¼šé…åˆé¥®é£Ÿè°ƒæ•´ï¼Œä¿ƒè¿›å¥åº·
4. **è§„å¾‹ä½œæ¯**ï¼šä¿è¯å……è¶³ç¡çœ ï¼Œæœ‰åŠ©è¥å…»å¸æ”¶

**è€å¹´äººè¥å…»è¦ç‚¹**ï¼š
- è›‹ç™½è´¨ï¼šé€‰æ‹©ä¼˜è´¨è›‹ç™½ï¼Œå¦‚é±¼ç±»ã€è±†ç±»
- é’™è´¨ï¼šå……è¶³çš„å¥¶åˆ¶å“å’Œç»¿å¶è”¬èœ
- ç»´ç”Ÿç´ ï¼šå¤šç§ç»´ç”Ÿç´ çš„å‡è¡¡è¡¥å……
- æ°´åˆ†ï¼šæ¯æ—¥1200-1500mlçš„å……è¶³é¥®æ°´

**æ¸©é¦¨æé†’**ï¼š
æ¯ä¸ªäººçš„èº«ä½“çŠ¶å†µä¸åŒï¼Œå»ºè®®æ ¹æ®ä¸ªäººæƒ…å†µè°ƒæ•´é¥®é£Ÿã€‚å¦‚æœ‰ç‰¹æ®Šç–¾ç—…æˆ–ç”¨è¯æƒ…å†µï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿæˆ–è¥å…»å¸ˆã€‚

å¦‚æ‚¨éœ€è¦æ›´å…·ä½“çš„å»ºè®®ï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„å¥åº·çŠ¶å†µä¿¡æ¯ã€‚"""
        
        return base_response
    
    def _adjust_response_style(self, answer: str, style: str) -> str:
        """è°ƒæ•´å›ç­”é£æ ¼"""
        if style == "friendly":
            # æ·»åŠ æ›´äº²åˆ‡çš„è¡¨è¾¾
            answer = answer.replace("æ‚¨å¥½ï¼", "æ‚¨å¥½å‘€ï¼äº²çˆ±çš„æœ‹å‹ï¼Œ")
            answer = answer.replace("å»ºè®®", "å»ºè®®æ‚¨")
            answer += "\n\næ„¿æ‚¨èº«ä½“å¥åº·ï¼Œç”Ÿæ´»æ„‰å¿«ï¼ğŸŒ¸"
        elif style == "detailed":
            # æ·»åŠ æ›´å¤šç»†èŠ‚è¯´æ˜
            answer += "\n\n**è¡¥å……è¯´æ˜**ï¼šä»¥ä¸Šå»ºè®®åŸºäºä¸€èˆ¬è€å¹´äººè¥å…»éœ€æ±‚åˆ¶å®šï¼Œå…·ä½“å®æ–½æ—¶è¯·è€ƒè™‘ä¸ªäººä½“è´¨ã€ç–¾ç—…çŠ¶å†µå’Œé¥®é£Ÿä¹ æƒ¯ã€‚"
        
        return answer
    
    def _calculate_confidence(self, prompt: str, answer: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        confidence = 0.8  # åŸºç¡€ç½®ä¿¡åº¦
        
        # åŸºäºpromptè´¨é‡è°ƒæ•´
        if len(prompt) > 1000:
            confidence += 0.1
        
        # åŸºäºå›ç­”å®Œæ•´æ€§è°ƒæ•´
        if len(answer) > 500:
            confidence += 0.05
        
        if "æ³¨æ„äº‹é¡¹" in answer:
            confidence += 0.05
        
        return min(confidence, 1.0)
    
    def _load_response_templates(self) -> Dict[str, str]:
        """åŠ è½½å›ç­”æ¨¡æ¿"""
        return {
            "greeting": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„è¥å…»å’¨è¯¢åŠ©æ‰‹ã€‚",
            "closing": "å¸Œæœ›è¿™äº›å»ºè®®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼",
            "disclaimer": "ä»¥ä¸Šå»ºè®®ä»…ä¾›å‚è€ƒï¼Œå…·ä½“æƒ…å†µè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚"
        }


class QualityAssessment:
    """è´¨é‡è¯„ä¼°å™¨"""
    
    def __init__(self):
        pass
    
    def assess_response(
        self, 
        response: RAGResponse, 
        context: RAGContext
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°å›ç­”è´¨é‡
        
        Args:
            response: RAGå“åº”
            context: ä¸Šä¸‹æ–‡
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        assessment = {
            "overall_score": 0.0,
            "dimensions": {},
            "issues": [],
            "suggestions": []
        }
        
        # 1. ç›¸å…³æ€§è¯„ä¼°
        relevance_score = self._assess_relevance(response, context)
        assessment["dimensions"]["relevance"] = relevance_score
        
        # 2. å®Œæ•´æ€§è¯„ä¼°
        completeness_score = self._assess_completeness(response)
        assessment["dimensions"]["completeness"] = completeness_score
        
        # 3. å‡†ç¡®æ€§è¯„ä¼°
        accuracy_score = self._assess_accuracy(response)
        assessment["dimensions"]["accuracy"] = accuracy_score
        
        # 4. å¯è¯»æ€§è¯„ä¼°
        readability_score = self._assess_readability(response)
        assessment["dimensions"]["readability"] = readability_score
        
        # 5. å®‰å…¨æ€§è¯„ä¼°
        safety_score = self._assess_safety(response)
        assessment["dimensions"]["safety"] = safety_score
        
        # è®¡ç®—æ€»åˆ†
        weights = {
            "relevance": 0.3,
            "completeness": 0.25,
            "accuracy": 0.25,
            "readability": 0.1,
            "safety": 0.1
        }
        
        assessment["overall_score"] = sum(
            assessment["dimensions"][dim] * weight 
            for dim, weight in weights.items()
        )
        
        # ç”Ÿæˆé—®é¢˜å’Œå»ºè®®
        assessment["issues"], assessment["suggestions"] = self._generate_feedback(
            assessment["dimensions"]
        )
        
        return assessment
    
    def _assess_relevance(self, response: RAGResponse, context: RAGContext) -> float:
        """è¯„ä¼°ç›¸å…³æ€§"""
        score = 80.0  # åŸºç¡€åˆ†æ•°
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        query_words = set(context.user_query.lower().split())
        answer_words = set(response.answer.lower().split())
        
        overlap = len(query_words.intersection(answer_words))
        if overlap > 0:
            score += min(overlap * 5, 20)
        
        return min(score, 100.0)
    
    def _assess_completeness(self, response: RAGResponse) -> float:
        """è¯„ä¼°å®Œæ•´æ€§"""
        score = 70.0
        
        # æ£€æŸ¥å›ç­”é•¿åº¦
        if len(response.answer) > 300:
            score += 10
        if len(response.answer) > 600:
            score += 10
        
        # æ£€æŸ¥ç»“æ„åŒ–ç¨‹åº¦
        if "**" in response.answer:
            score += 5
        if "å»ºè®®" in response.answer:
            score += 5
        if "æ³¨æ„" in response.answer:
            score += 5
        
        return min(score, 100.0)
    
    def _assess_accuracy(self, response: RAGResponse) -> float:
        """è¯„ä¼°å‡†ç¡®æ€§"""
        score = 85.0  # åŸºäºæ¨¡æ¿çš„å›ç­”é€šå¸¸å‡†ç¡®æ€§è¾ƒé«˜
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¥æºæ”¯æŒ
        if len(response.sources) > 0:
            score += 10
        
        # æ£€æŸ¥ç½®ä¿¡åº¦
        score += response.confidence_score * 5
        
        return min(score, 100.0)
    
    def _assess_readability(self, response: RAGResponse) -> float:
        """è¯„ä¼°å¯è¯»æ€§"""
        score = 80.0
        
        answer = response.answer
        
        # æ£€æŸ¥å¥å­é•¿åº¦
        sentences = answer.split('ã€‚')
        avg_length = sum(len(s) for s in sentences) / len(sentences) if sentences else 0
        
        if 10 <= avg_length <= 30:  # é€‚ä¸­çš„å¥å­é•¿åº¦
            score += 10
        
        # æ£€æŸ¥æ ¼å¼åŒ–
        if '\n' in answer:
            score += 5
        
        return min(score, 100.0)
    
    def _assess_safety(self, response: RAGResponse) -> float:
        """è¯„ä¼°å®‰å…¨æ€§"""
        score = 90.0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…è´£å£°æ˜æˆ–åŒ»å˜±å»ºè®®
        if "å’¨è¯¢åŒ»ç”Ÿ" in response.answer or "åŒ»ç”Ÿ" in response.answer:
            score += 10
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å±é™©å»ºè®®ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        dangerous_words = ["å¤§é‡", "éšæ„", "ä¸éœ€è¦"]
        for word in dangerous_words:
            if word in response.answer:
                score -= 10
        
        return max(score, 0.0)
    
    def _generate_feedback(self, dimensions: Dict[str, float]) -> Tuple[List[str], List[str]]:
        """ç”Ÿæˆé—®é¢˜å’Œå»ºè®®"""
        issues = []
        suggestions = []
        
        for dim, score in dimensions.items():
            if score < 70:
                if dim == "relevance":
                    issues.append("å›ç­”ä¸é—®é¢˜ç›¸å…³æ€§ä¸å¤Ÿ")
                    suggestions.append("å»ºè®®å¢åŠ æ›´å¤šä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³çš„å†…å®¹")
                elif dim == "completeness":
                    issues.append("å›ç­”ä¸å¤Ÿå®Œæ•´")
                    suggestions.append("å»ºè®®è¡¥å……æ›´å¤šç»†èŠ‚å’Œå…·ä½“å»ºè®®")
                elif dim == "accuracy":
                    issues.append("å›ç­”å‡†ç¡®æ€§æœ‰å¾…æé«˜")
                    suggestions.append("å»ºè®®åŸºäºæ›´å¤šå¯é æ¥æºç”Ÿæˆå›ç­”")
                elif dim == "readability":
                    issues.append("å›ç­”å¯è¯»æ€§éœ€è¦æ”¹å–„")
                    suggestions.append("å»ºè®®ä¼˜åŒ–æ®µè½ç»“æ„å’Œè¡¨è¾¾æ–¹å¼")
                elif dim == "safety":
                    issues.append("å›ç­”å®‰å…¨æ€§éœ€è¦æ³¨æ„")
                    suggestions.append("å»ºè®®æ·»åŠ é€‚å½“çš„å…è´£å£°æ˜å’ŒåŒ»å˜±æé†’")
        
        return issues, suggestions


class RAGChain:
    """RAG Chain ä¸»ç±»"""
    
    def __init__(
        self, 
        vector_store: VectorStore,
        config: RAGConfig = None
    ):
        """
        åˆå§‹åŒ–RAG Chain
        
        Args:
            vector_store: å‘é‡å­˜å‚¨
            config: RAGé…ç½®
        """
        self.config = config or RAGConfig()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.retriever = ElderNutritionRetriever(vector_store)
        self.prompt_manager = PromptManager()
        self.response_generator = ResponseGenerator(config=self.config)
        self.quality_assessor = QualityAssessment()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_queries": 0,
            "successful_responses": 0,
            "average_processing_time": 0.0,
            "average_quality_score": 0.0
        }
    
    def process_query(
        self, 
        user_query: str,
        context: RAGContext = None
    ) -> RAGResponse:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„ä¸»æ–¹æ³•
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            RAGå“åº”ç»“æœ
        """
        start_time = time.time()
        
        # åˆ›å»ºé»˜è®¤ä¸Šä¸‹æ–‡
        if context is None:
            context = RAGContext(
                user_query=user_query,
                session_id=f"session_{int(time.time())}"
            )
        
        try:
            # 1. çŸ¥è¯†æ£€ç´¢
            search_results = self._retrieve_knowledge(user_query)
            
            # 2. Promptç”Ÿæˆ
            prompt, intent = self._generate_prompt(user_query, search_results, context)
            
            # 3. å›ç­”ç”Ÿæˆ
            answer, confidence = self._generate_answer(prompt, context)
            
            # 4. è´¨é‡è¯„ä¼°
            processing_time = time.time() - start_time
            
            response = RAGResponse(
                query=user_query,
                answer=answer,
                sources=search_results,
                confidence_score=confidence,
                quality_score=0.0,  # å¾…è¯„ä¼°
                processing_time=processing_time,
                intent=intent,
                prompt_used=prompt
            )
            
            # è´¨é‡è¯„ä¼°
            if self.config.enable_quality_check:
                quality_assessment = self.quality_assessor.assess_response(response, context)
                response.quality_score = quality_assessment["overall_score"]
                response.metadata["quality_assessment"] = quality_assessment
            
            # æ›´æ–°ç»Ÿè®¡
            self._update_stats(response)
            
            return response
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_response = RAGResponse(
                query=user_query,
                answer=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†é”™è¯¯ï¼š{str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–é‡æ–°è¡¨è¿°é—®é¢˜ã€‚",
                sources=[],
                confidence_score=0.0,
                quality_score=0.0,
                processing_time=time.time() - start_time,
                intent=QueryIntent.GENERAL_NUTRITION,
                prompt_used="",
                metadata={"error": str(e)}
            )
            
            return error_response
    
    def _retrieve_knowledge(self, user_query: str) -> List[SearchResult]:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        search_config = SearchConfig(
            strategy=self.config.search_strategy,
            top_k=self.config.top_k,
            similarity_threshold=self.config.similarity_threshold,
            enable_reranking=self.config.enable_reranking
        )
        
        return self.retriever.search(user_query, search_config)
    
    def _generate_prompt(
        self, 
        user_query: str, 
        search_results: List[SearchResult],
        context: RAGContext
    ) -> Tuple[str, QueryIntent]:
        """ç”ŸæˆPrompt"""
        prompt = self.prompt_manager.generate_prompt(
            user_query=user_query,
            search_results=search_results,
            use_few_shot=self.config.use_few_shot,
            user_profile=context.user_profile
        )
        
        # è·å–è¯†åˆ«çš„æ„å›¾
        analysis = self.prompt_manager.analyze_query_complexity(user_query)
        intent = analysis["primary_intent"][0]
        
        return prompt, intent
    
    def _generate_answer(self, prompt: str, context: RAGContext) -> Tuple[str, float]:
        """ç”Ÿæˆå›ç­”"""
        answer, confidence = self.response_generator.generate_response(
            prompt=prompt,
            config=self.config,
            context=context
        )
        
        # é•¿åº¦æ§åˆ¶
        if len(answer) > self.config.max_response_length:
            answer = answer[:self.config.max_response_length] + "..."
        
        return answer, confidence
    
    def _update_stats(self, response: RAGResponse):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_queries"] += 1
        
        if response.confidence_score > 0.5:
            self.stats["successful_responses"] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_time = self.stats["average_processing_time"] * (self.stats["total_queries"] - 1)
        self.stats["average_processing_time"] = (total_time + response.processing_time) / self.stats["total_queries"]
        
        # æ›´æ–°å¹³å‡è´¨é‡åˆ†æ•°
        if response.quality_score > 0:
            total_quality = self.stats["average_quality_score"] * (self.stats["total_queries"] - 1)
            self.stats["average_quality_score"] = (total_quality + response.quality_score) / self.stats["total_queries"]
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.copy()
    
    def update_config(self, new_config: RAGConfig):
        """æ›´æ–°é…ç½®"""
        self.config = new_config
        # å¦‚æœResponseGeneratoréœ€è¦æ›´æ–°LLMé…ç½®ï¼Œé‡æ–°åˆå§‹åŒ–
        if (new_config.use_real_llm != self.response_generator.config.use_real_llm or
            new_config.llm_provider != self.response_generator.config.llm_provider):
            self.response_generator = ResponseGenerator(config=new_config)
        else:
            self.response_generator.config = new_config 