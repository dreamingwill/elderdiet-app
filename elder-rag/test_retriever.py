#!/usr/bin/env python3
"""
æ£€ç´¢å™¨åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯æ™ºèƒ½æ£€ç´¢ã€æŸ¥è¯¢åˆ†æã€ç»“æœè¿‡æ»¤ç­‰åŠŸèƒ½
"""

import sys
import os
import json
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from services.vector_store import VectorStore
from services.retriever import (
    ElderNutritionRetriever, 
    SearchConfig, 
    SearchStrategy,
    QueryProcessor,
    ResultProcessor
)
from utils.text_processor import TextProcessor


def setup_test_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    print("ğŸš€ åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ")
    print("="*60)
    
    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
    print("æ­£åœ¨åŠ è½½å‘é‡æ•°æ®åº“...")
    vector_store = VectorStore(model_name="shibing624/text2vec-base-chinese")
    
    # å°è¯•åŠ è½½å·²å­˜åœ¨çš„æ•°æ®åº“
    db_path = "data/vector_db"
    if os.path.exists(db_path):
        vector_store.load(db_path)
        print(f"âœ… å·²åŠ è½½ç°æœ‰æ•°æ®åº“: {vector_store.get_stats()['total_documents']} ä¸ªæ–‡æ¡£")
    else:
        print("âŒ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®åº“ï¼Œè¯·å…ˆè¿è¡Œ test_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
        return None
    
    return vector_store


def test_query_processor():
    """æµ‹è¯•æŸ¥è¯¢å¤„ç†å™¨"""
    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•æŸ¥è¯¢å¤„ç†å™¨")
    print("="*60)
    
    text_processor = TextProcessor()
    query_processor = QueryProcessor(text_processor)
    
    # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
    test_queries = [
        "ç³–å°¿ç—…è€äººåº”è¯¥åƒä»€ä¹ˆï¼Ÿ",
        "é«˜è¡€å‹æ‚£è€…è¥å…»å»ºè®®",
        "è€å¹´äººç¼ºé’™",
        "ä¾¿ç§˜æ€ä¹ˆåŠ",
        "å¦‚ä½•æå‡å…ç–«åŠ›å’ŒæŠµæŠ—åŠ›ï¼Ÿ",
        "ç‡•éº¦å¯¹å¿ƒè¡€ç®¡æœ‰ä»€ä¹ˆå¥½å¤„"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ” æŸ¥è¯¢ {i}: {query}")
        analysis = query_processor.analyze_query(query)
        
        print(f"  æ¸…æ´—å: {analysis['clean_query']}")
        print(f"  å…³é”®è¯: {analysis['keywords']}")
        print(f"  æ„å›¾: {analysis['intent']}")
        print(f"  å¤æ‚åº¦: {analysis['complexity']}")
        
        # æµ‹è¯•æŸ¥è¯¢æ‰©å±•
        expanded = query_processor.expand_query(analysis)
        if len(expanded) > 1:
            print(f"  æ‰©å±•æŸ¥è¯¢: {expanded[1:]}")


def test_search_strategies(retriever):
    """æµ‹è¯•ä¸åŒæ£€ç´¢ç­–ç•¥"""
    print("\n" + "="*60)
    print("ğŸ¯ æµ‹è¯•æ£€ç´¢ç­–ç•¥")
    print("="*60)
    
    test_query = "ç³–å°¿ç—…è€äººé¥®é£Ÿæ³¨æ„äº‹é¡¹"
    strategies = [
        (SearchStrategy.SEMANTIC_ONLY, "çº¯è¯­ä¹‰æ£€ç´¢"),
        (SearchStrategy.KEYWORD_ENHANCED, "å…³é”®è¯å¢å¼ºæ£€ç´¢"),
        (SearchStrategy.HYBRID, "æ··åˆæ£€ç´¢"),
        (SearchStrategy.MULTI_QUERY, "å¤šæŸ¥è¯¢æ£€ç´¢")
    ]
    
    for strategy, strategy_name in strategies:
        print(f"\nğŸ“Š {strategy_name}")
        print("-" * 40)
        
        config = SearchConfig(
            strategy=strategy,
            top_k=3,
            similarity_threshold=0.2,
            enable_reranking=True
        )
        
        start_time = time.time()
        results = retriever.search(test_query, config)
        search_time = time.time() - start_time
        
        print(f"æ£€ç´¢æ—¶é—´: {search_time:.3f}s")
        print(f"ç»“æœæ•°é‡: {len(results)}")
        
        for j, result in enumerate(results, 1):
            print(f"  {j}. {result.title}")
            print(f"     è¯­ä¹‰ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
            print(f"     ç»¼åˆç›¸å…³æ€§: {result.relevance_score:.4f}")
            print(f"     æ‘˜è¦: {result.snippet[:60]}...")


def test_advanced_search_features(retriever):
    """æµ‹è¯•é«˜çº§æ£€ç´¢åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ§  æµ‹è¯•é«˜çº§æ£€ç´¢åŠŸèƒ½")
    print("="*60)
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
    advanced_queries = [
        {
            "query": "è€å¹´äººé«˜è¡€å‹æ‚£è€…èƒ½åƒä»€ä¹ˆè”¬èœï¼Ÿ",
            "description": "å¤åˆæ¡ä»¶æŸ¥è¯¢ï¼ˆå¹´é¾„+ç–¾ç—…+é£Ÿç‰©ç±»å‹ï¼‰"
        },
        {
            "query": "ç»´ç”Ÿç´ Dä¸è¶³æ€ä¹ˆè¡¥å……",
            "description": "è¥å…»ç´ ç¼ºä¹æŸ¥è¯¢"
        },
        {
            "query": "å¿ƒè¡€ç®¡ç–¾ç—…é¢„é˜²",
            "description": "ç–¾ç—…é¢„é˜²æŸ¥è¯¢"
        },
        {
            "query": "æ¶ˆåŒ–ä¸è‰¯çš„è€äººåº”è¯¥é¿å…å“ªäº›é£Ÿç‰©",
            "description": "ç—‡çŠ¶+é¥®é£Ÿç¦å¿ŒæŸ¥è¯¢"
        }
    ]
    
    for test_case in advanced_queries:
        query = test_case["query"]
        description = test_case["description"]
        
        print(f"\nğŸ” {description}")
        print(f"æŸ¥è¯¢: {query}")
        print("-" * 40)
        
        # ä½¿ç”¨æ··åˆæ£€ç´¢ç­–ç•¥
        config = SearchConfig(
            strategy=SearchStrategy.HYBRID,
            top_k=3,
            similarity_threshold=0.25,
            enable_reranking=True
        )
        
        results = retriever.search(query, config)
        
        if results:
            for i, result in enumerate(results, 1):
                print(f"  {i}. ã€{result.category}ã€‘{result.title}")
                print(f"     ç›¸å…³æ€§: {result.relevance_score:.4f} | ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
                print(f"     å…³é”®è¯: {', '.join(result.keywords[:5])}")
                print(f"     å†…å®¹: {result.snippet}")
                print()
        else:
            print("  âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")


def test_threshold_filtering(retriever):
    """æµ‹è¯•é˜ˆå€¼è¿‡æ»¤åŠŸèƒ½"""
    print("\n" + "="*60)
    print("âš–ï¸  æµ‹è¯•é˜ˆå€¼è¿‡æ»¤åŠŸèƒ½")
    print("="*60)
    
    test_query = "è‚Œè‚‰é”»ç‚¼è¥å…»è¡¥å……"
    thresholds = [0.1, 0.3, 0.5, 0.7]
    
    for threshold in thresholds:
        print(f"\nğŸšï¸  ç›¸ä¼¼åº¦é˜ˆå€¼: {threshold}")
        print("-" * 30)
        
        config = SearchConfig(
            strategy=SearchStrategy.SEMANTIC_ONLY,
            top_k=5,
            similarity_threshold=threshold,
            enable_reranking=False
        )
        
        results = retriever.search(test_query, config)
        print(f"ç»“æœæ•°é‡: {len(results)}")
        
        for result in results:
            print(f"  {result.title} (ç›¸ä¼¼åº¦: {result.similarity_score:.4f})")


def test_performance_comparison(retriever):
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\n" + "="*60)
    print("âš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    
    test_queries = [
        "ç³–å°¿ç—…é¥®é£Ÿå»ºè®®",
        "é«˜è¡€å‹è¥å…»ç®¡ç†",
        "è€å¹´äººé’™è´¨è¡¥å……",
        "å¿ƒè¡€ç®¡ç–¾ç—…é¢„é˜²",
        "æ¶ˆåŒ–ç³»ç»Ÿå¥åº·"
    ]
    
    configs = [
        (SearchConfig(strategy=SearchStrategy.SEMANTIC_ONLY, enable_reranking=False), "åŸºç¡€è¯­ä¹‰æ£€ç´¢"),
        (SearchConfig(strategy=SearchStrategy.HYBRID, enable_reranking=True), "æ··åˆæ£€ç´¢+é‡æ’åº")
    ]
    
    for config, config_name in configs:
        print(f"\nğŸ“Š {config_name}")
        print("-" * 30)
        
        total_time = 0
        total_results = 0
        
        for query in test_queries:
            start_time = time.time()
            results = retriever.search(query, config)
            search_time = time.time() - start_time
            
            total_time += search_time
            total_results += len(results)
        
        avg_time = total_time / len(test_queries)
        avg_results = total_results / len(test_queries)
        
        print(f"  å¹³å‡æ£€ç´¢æ—¶é—´: {avg_time:.3f}s")
        print(f"  å¹³å‡ç»“æœæ•°é‡: {avg_results:.1f}")
        print(f"  æ€»æ£€ç´¢æ—¶é—´: {total_time:.3f}s")


def test_edge_cases(retriever):
    """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
    print("\n" + "="*60)
    print("ğŸ”¬ è¾¹ç¼˜æƒ…å†µæµ‹è¯•")
    print("="*60)
    
    edge_cases = [
        ("", "ç©ºæŸ¥è¯¢"),
        ("a", "å•å­—ç¬¦æŸ¥è¯¢"),
        ("ç³–å°¿ç—…" * 50, "è¶…é•¿æŸ¥è¯¢"),
        ("xyz123", "æ— æ„ä¹‰æŸ¥è¯¢"),
        ("ï¼Ÿï¼Ÿï¼Ÿ", "ç‰¹æ®Šå­—ç¬¦æŸ¥è¯¢"),
        ("è€å¹´äººè€å¹´äººè€å¹´äºº", "é‡å¤è¯æŸ¥è¯¢")
    ]
    
    for query, description in edge_cases:
        print(f"\nğŸ§ª {description}: '{query[:50]}{'...' if len(query) > 50 else ''}'")
        
        try:
            results = retriever.search(query)
            print(f"  âœ… ç»“æœæ•°é‡: {len(results)}")
            if results:
                print(f"  æœ€é«˜ç›¸ä¼¼åº¦: {results[0].similarity_score:.4f}")
        except Exception as e:
            print(f"  âŒ é”™è¯¯: {str(e)}")


def generate_retriever_report(retriever):
    """ç”Ÿæˆæ£€ç´¢å™¨æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“‹ æ£€ç´¢å™¨åŠŸèƒ½æŠ¥å‘Š")
    print("="*60)
    
    stats = retriever.get_search_stats()
    
    print("ğŸ—ï¸  ç³»ç»Ÿé…ç½®:")
    print(f"  å‘é‡æ¨¡å‹: {stats['vector_store_stats']['model_name']}")
    print(f"  å‘é‡ç»´åº¦: {stats['vector_store_stats']['vector_dimension']}")
    print(f"  æ–‡æ¡£æ€»æ•°: {stats['vector_store_stats']['total_documents']}")
    
    print("\nğŸ›ï¸  æ£€ç´¢é…ç½®:")
    for key, value in stats['config'].items():
        print(f"  {key}: {value}")
    
    print("\nâœ… å·²å®ç°åŠŸèƒ½:")
    features = [
        "âœ“ å¤šç§æ£€ç´¢ç­–ç•¥ (è¯­ä¹‰/å…³é”®è¯/æ··åˆ/å¤šæŸ¥è¯¢)",
        "âœ“ æŸ¥è¯¢æ„å›¾åˆ†æå’Œåˆ†ç±»",
        "âœ“ æŸ¥è¯¢æ‰©å±•å’Œæ”¹å†™",
        "âœ“ ç»“æœè¿‡æ»¤å’Œé˜ˆå€¼æ§åˆ¶",
        "âœ“ æ™ºèƒ½é‡æ’åºç®—æ³•",
        "âœ“ ç»“æœæ‘˜è¦ç”Ÿæˆ",
        "âœ“ æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜",
        "âœ“ è¾¹ç¼˜æƒ…å†µå¤„ç†"
    ]
    
    for feature in features:
        print(f"  {feature}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ElderDiet RAG æ£€ç´¢å™¨æµ‹è¯•")
    print("="*60)
    
    try:
        # 1. è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        vector_store = setup_test_environment()
        if not vector_store:
            return
        
        # 2. åˆå§‹åŒ–æ£€ç´¢å™¨
        print("\næ­£åœ¨åˆå§‹åŒ–æ£€ç´¢å™¨...")
        retriever = ElderNutritionRetriever(vector_store)
        print("âœ… æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # 3. æ‰§è¡Œå„é¡¹æµ‹è¯•
        test_query_processor()
        test_search_strategies(retriever)
        test_advanced_search_features(retriever)
        test_threshold_filtering(retriever)
        test_performance_comparison(retriever)
        test_edge_cases(retriever)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        generate_retriever_report(retriever)
        
        print("\n" + "="*60)
        print("ğŸ‰ æ£€ç´¢å™¨æµ‹è¯•å®Œæˆï¼")
        print("="*60)
        
        # 5. ç®€å•äº¤äº’æµ‹è¯•
        print("\nğŸ’¬ äº¤äº’å¼æµ‹è¯• (è¾“å…¥ 'quit' é€€å‡º):")
        while True:
            query = input("\nè¯·è¾“å…¥æŸ¥è¯¢: ").strip()
            if query.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                break
            
            if query:
                print("ğŸ” æ£€ç´¢ä¸­...")
                results = retriever.search(query)
                
                print(f"\nğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
                for i, result in enumerate(results, 1):
                    print(f"\n{i}. ã€{result.category}ã€‘{result.title}")
                    print(f"   ç›¸å…³æ€§: {result.relevance_score:.4f} | ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
                    print(f"   {result.snippet}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 